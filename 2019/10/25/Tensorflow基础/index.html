<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8" />

    

    

    <title>Tensorflow基础 | 小于狙击手的博客</title>
    <meta name="author" content="于印霄" />
    <meta name="keywords" content="null" />
    <meta name="description" content="Tensorflow首先通过将程序分为两个独立的部分，包括计算图的定义及其执行。图定义和执行的分开设计让 TensorFlow 能够多平台工作以及并行执行。计算图：是包含节点和边的网络。定义所有要使用的数据，也就是张量（tensor）对象（常量、变量和占位符），同时定义要执行的所有计算，即运算操作对象（Operation Object，简称 OP）。每个节点可以有零个或多个输入，但只有一个输出。网络中的节点表示对象（张量和运算操作），边表示运算操作之间流动的张量。一、数据类型..." />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />

    
    <link rel="alternate" href="/atom.xml" title="小于狙击手的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/images/favicon.ico">
    

    <style type="text/css">
    @font-face {
        font-family: 'icomoon';
        src: url("/fonts/icomoon.eot?q628ml");
        src: url("/fonts/icomoon.eot?q628ml#iefix") format('embedded-opentype'),
             url("/fonts/icomoon.ttf?q628ml") format('truetype'),
             url("/fonts/icomoon.woff?q628ml") format('woff'),
             url("/fonts/icomoon.svg?q628ml#icomoon") format('svg');
        font-weight: normal;
        font-style: normal;
    }
    </style>
    <link rel="stylesheet" href="/css/style.css">

    <!--[if lt IE 9]>
    <style type="text/css">
    .nav-inner {top:0;}
    .author-meta {position:static;top:0;}
    .search-form {height:36px;}
    </style>
    <script type="text/javascript" src="https://unpkg.com/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
    <![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><main class="app">
        <header id="header" class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">小于狙击手的博客</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item" href="/categories/home">
                <span class="nav-text">首页</span>
            </a>
        
            <a class="nav-item" href="/categories/ml">
                <span class="nav-text">机器学习</span>
            </a>
        
            <a class="nav-item" href="/categories/rec">
                <span class="nav-text">推荐系统</span>
            </a>
        
            <a class="nav-item" href="/categories/BD">
                <span class="nav-text">大数据</span>
            </a>
        
            <a class="nav-item" href="/categories/code">
                <span class="nav-text">coding</span>
            </a>
        
            <a class="nav-item" href="/tags">
                <span class="nav-text">标签</span>
            </a>
        
            <a class="nav-item" href="/archives">
                <span class="nav-text">归档</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">关于我</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="https://yuyinxiao.github.io"></form>

        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Tensorflow"><span class="toc-number">1.</span> <span class="toc-text">Tensorflow</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、数据类型：常量、变量、占位符"><span class="toc-number">1.1.</span> <span class="toc-text">一、数据类型：常量、变量、占位符</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#常量"><span class="toc-number">1.1.1.</span> <span class="toc-text">常量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#变量"><span class="toc-number">1.1.2.</span> <span class="toc-text">变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#占位符"><span class="toc-number">1.1.3.</span> <span class="toc-text">占位符</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、Tensorflow的重要API"><span class="toc-number">1.2.</span> <span class="toc-text">二、Tensorflow的重要API</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、Tenforflow实现线性回归"><span class="toc-number">1.3.</span> <span class="toc-text">三、Tenforflow实现线性回归</span></a></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content">
            <div id="wrapper" class="wrapper" style="max-width: 800px">
                <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            Tensorflow基础
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://yuyinxiao.github.io/2019/10/25/Tensorflow%E5%9F%BA%E7%A1%80/index.html">
    
        <!-- 不蒜子统计 -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">阅读数 <span id="busuanzi_value_site_pv"></span>次</span>
    

    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-10-25T05:42:39.000Z" itemprop="datePublished">2019-10-25</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/DL/" rel="tag">DL</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h1><ul>
<li>首先通过将程序分为两个独立的部分，包括计算图的定义及其执行。</li>
<li>图定义和执行的分开设计让 TensorFlow 能够多平台工作以及并行执行。</li>
<li>计算图：是包含节点和边的网络。定义所有要使用的数据，也就是张量（tensor）对象（常量、变量和占位符），同时定义要执行的所有计算，即运算操作对象（Operation Object，简称 OP）。</li>
<li>每个节点可以有零个或多个输入，但只有一个输出。网络中的节点表示对象（张量和运算操作），边表示运算操作之间流动的张量。</li>
</ul>
<hr>
<h2 id="一、数据类型：常量、变量、占位符"><a href="#一、数据类型：常量、变量、占位符" class="headerlink" title="一、数据类型：常量、变量、占位符"></a>一、数据类型：常量、变量、占位符</h2><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><p>常量是其值不能改变的张量；常量存储在计算图的定义中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(<span class="number">4</span>);</span><br><span class="line">tf.constant([<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line">tf.zeros([M,N],tf.dtype)</span><br><span class="line">tf.zeros([<span class="number">2</span>,<span class="number">3</span>],tf.int32)</span><br><span class="line">tf.ones([M,N],tf,dtype)</span><br><span class="line">range_t = tf.linspace(<span class="number">2.0</span>,<span class="number">5.0</span>,<span class="number">4</span>)  <span class="comment">#等差数列，差值=(5-2)/(4-1)</span></span><br><span class="line">range_t = tf.range(<span class="number">10</span>) <span class="comment">#同python range</span></span><br><span class="line">tf.random_normal([shape],mean=<span class="number">2.0</span>,stddev=<span class="number">4</span>,seed=<span class="number">12</span>)</span><br></pre></td></tr></table></figure><br><a id="more"></a></p>
<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>在神经网络中的权重声明为变量来实现，变量在使用前需要被显示初始化。另外需要注意的是，每次加载图时都会加载相关变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#常量初始变量</span></span><br><span class="line">weights=tf.Variable(tf.random_normal([m,n],stddev=<span class="number">2</span>))</span><br><span class="line">bias=tf.Variable(tf.zeros[<span class="number">100</span>],name=<span class="string">'bias'</span>)</span><br><span class="line">tf.Variable(tf.random_normal([self.feature_size,self.embedding_size],<span class="number">0.0</span>,<span class="number">0.01</span>),name=<span class="string">'feature_embeddings'</span>)</span><br><span class="line">tf.Variable(np.random.normal(loc=<span class="number">0</span>,scale=glorot,size(input_size,self.deep_layers[<span class="number">0</span>])),dtype=np.float32)</span><br><span class="line"><span class="comment">#变量初始变量</span></span><br><span class="line">weights_2=tf.Variable(weights.initialized_value,name=<span class="string">'w2'</span>)</span><br><span class="line">intial_op=tf.global_variables_initializer()</span><br></pre></td></tr></table></figure></p>
<h3 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h3><p>和 feed_dict 一起使用于将训练数据输入TensorFlow图中。在session运行计算图时，为占位符赋值。占位符不包含任何数据，只是数据的入口；<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x=tf.placeholder(dtype,shape=<span class="literal">None</span>,name=<span class="literal">None</span>)</span><br><span class="line">y=<span class="number">2</span>*x</span><br><span class="line">data=tf.random_uniform([<span class="number">4</span>,<span class="number">5</span>],<span class="number">10</span>);</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    x_data=sess.run(data)</span><br><span class="line">    print(sess.run(y,feed_dict=&#123;x:x_data&#125;))</span><br></pre></td></tr></table></figure></p>
<h2 id="二、Tensorflow的重要API"><a href="#二、Tensorflow的重要API" class="headerlink" title="二、Tensorflow的重要API"></a>二、Tensorflow的重要API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##输入输出 占位符</span></span><br><span class="line">tf.placeholder(tf.int32,shape=[<span class="literal">None</span>,<span class="literal">None</span>],name=<span class="string">'feat_index'</span>)</span><br><span class="line"><span class="comment">##embedding_lookup</span></span><br><span class="line">tf.nn.embedding_lookup(self.weights[<span class="string">'feature_embeddings'</span>],self.feat_index)</span><br><span class="line"><span class="comment">##改变维度</span></span><br><span class="line">tf.reshape(self.feat_value,shape=[<span class="number">-1</span>,self.field_size,<span class="number">1</span>])</span><br><span class="line"><span class="comment">##矩阵点乘</span></span><br><span class="line">tf.multiply(self.embeddings,feat_value)</span><br><span class="line"><span class="comment">##矩阵乘法</span></span><br><span class="line">tf.matmul(self.y_deep,self.weights[<span class="string">"layer_%d"</span> %i])</span><br><span class="line"><span class="comment">##矩阵加法</span></span><br><span class="line">tf.add(self.weights[<span class="string">"aa"</span>], self.weights[<span class="string">"bias_%d"</span>%i])</span><br><span class="line"><span class="comment">##dropout</span></span><br><span class="line">tf.nn.dropout(self.y_deep,self.dropout_keep_deep[i+<span class="number">1</span>])</span><br><span class="line"><span class="comment">##激活函数</span></span><br><span class="line">tf.sigmoid(x)  <span class="comment">#梯度消失严重</span></span><br><span class="line">tf.tanh(x)  <span class="comment">#会出现梯度消失</span></span><br><span class="line">tf.nn.relu(x)  <span class="comment">#神经元稀疏失活，leakrelu</span></span><br><span class="line">tf.nn.softmax(x)    <span class="comment">#多分类中表示一个类的概率</span></span><br><span class="line"><span class="comment">##损失函数</span></span><br><span class="line">self.loss = tf.losses.log_loss(self.label, self.out)</span><br><span class="line">self.loss = tf.nn.l2_loss(tf.subtract(self.label, self.out))</span><br><span class="line"><span class="comment">##优化器</span></span><br><span class="line">self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=<span class="number">0.9</span>, beta2=<span class="number">0.999</span>,epsilon=<span class="number">1e-8</span>).minimize(self.loss)</span><br><span class="line">self.optimizer = tf.train.AdagradOptimizer(learning_rate=self.learning_rate，initial_accumulator_value=<span class="number">1e-8</span>).minimize(self.loss)</span><br><span class="line"><span class="comment">##运行</span></span><br><span class="line">feed_dict = &#123;</span><br><span class="line">    self.feat_index: Xi,</span><br><span class="line">    self.feat_value: Xv,</span><br><span class="line">    self.label: y,</span><br><span class="line">    self.dropout_keep_deep: [<span class="number">1.0</span>] * len(self.dropout_dep),</span><br><span class="line">    self.train_phase: <span class="literal">True</span>&#125;</span><br><span class="line">loss,opt = self.sess.run([self.loss,self.optimizer],feed_dict=feed_dict)</span><br></pre></td></tr></table></figure>
<h2 id="三、Tenforflow实现线性回归"><a href="#三、Tenforflow实现线性回归" class="headerlink" title="三、Tenforflow实现线性回归"></a>三、Tenforflow实现线性回归</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#使用numpy生成200个随机点</span></span><br><span class="line">x_data=np.linspace(<span class="number">-0.5</span>,<span class="number">0.5</span>,<span class="number">200</span>)[:,np.newaxis]</span><br><span class="line">noise=np.random.normal(<span class="number">0</span>,<span class="number">0.02</span>,x_data.shape)</span><br><span class="line">y_data=np.square(x_data)+noise</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义两个placeholder存放输入数据</span></span><br><span class="line">x=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">1</span>])</span><br><span class="line">y=tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义神经网络中间层</span></span><br><span class="line">Weights_L1=tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">biases_L1=tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>]))    <span class="comment">#加入偏置项</span></span><br><span class="line">Wx_plus_b_L1=tf.matmul(x,Weights_L1)+biases_L1</span><br><span class="line">L1=tf.nn.tanh(Wx_plus_b_L1)   <span class="comment">#加入激活函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义神经网络输出层</span></span><br><span class="line">Weights_L2=tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">biases_L2=tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>]))  <span class="comment">#加入偏置项</span></span><br><span class="line">Wx_plus_b_L2=tf.matmul(L1,Weights_L2)+biases_L2</span><br><span class="line">prediction=tf.nn.tanh(Wx_plus_b_L2)   <span class="comment">#加入激活函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义损失函数（均方差函数）</span></span><br><span class="line">loss=tf.reduce_mean(tf.square(y-prediction))</span><br><span class="line"><span class="comment">#定义反向传播算法（使用梯度下降算法训练）</span></span><br><span class="line">train_step=tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#变量初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment">#训练2000次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">        sess.run(train_step,feed_dict=&#123;x:x_data,y:y_data&#125;)</span><br><span class="line">    <span class="comment">#获得预测值</span></span><br><span class="line">    prediction_value=sess.run(prediction,feed_dict=&#123;x:x_data&#125;)</span><br></pre></td></tr></table></figure>

        
    </section>
</article>



<a id="pagenext" href="/2019/10/25/%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC%E6%95%B4%E7%90%86/" class="article-next" title="算法推导整理"><i class="icon-arrow-right"></i></a>


<a id="pageprev" href="/2019/10/25/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="article-prev" title="语言模型"><i class="icon-arrow-left"></i></a>



<div class="comments">
    <div id="comments"></div>
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>
    new Gitalk({
        clientID: "a9a645b881c78d12baa8",
        clientSecret: "d7e2f110f4885b3fa11894f3ddd2cd46523889fd",
        repo: "yuyinxiao.github.io",
        owner: "yuyinxiao",
        admin: ["yuyinxiao"],
        id: "2019/10/25/Tensorflow基础",
        distractionFreeMode: true,
        title: "Tensorflow基础",
        body: "https://yuyinxiao.github.io/2019/10/25/Tensorflow%E5%9F%BA%E7%A1%80/",
        labels: ["DL"]
    }).render('comments');
    </script>
</div>


            </div>
        </div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>

    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?ff62cebe12c54c12ef10722f77d75303";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    
    
        <!-- 不蒜子统计 -->
        <span id="busuanzi_container_site_pv">
                本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>
        <span class="post-meta-divider">|</span>
        <span id="busuanzi_container_site_uv" style='display:none'>
                本站访客数<span id="busuanzi_value_site_uv"></span>人
        </span>
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
</footer>

    </main>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }

            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle();
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp();
            }, 3000);
        }
    });
    </script>
    
        <script src="/js/scrollspy.min.js"></script>
        <script type="text/javascript">
        $(document.body).scrollspy({target: '#aside-inner'});

        $(window).on('resize', function() {
            var hw = $('#header').width();
            var ww = $('#wrapper').width();
            var space = ($(this).width() - hw - ww) / 2 / 2;

            var pageprev = $('#pageprev');
            var pagenext = $('#pagenext');
            var avg = (pageprev.width() + pagenext.width()) / 2

            if(space > avg) {
                var len = space - avg / 2;
                var styles = {position: 'fixed', top: '50%', marginTop: - (pageprev.width() + pagenext.width()) / 4}
                pageprev.css($.extend({left: hw + len}, styles));
                pagenext.css($.extend({right: len}, styles));
            } else {
                pageprev.removeAttr('style');
                pagenext.removeAttr('style');
            }
        }).trigger('resize');
        </script>
    

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
