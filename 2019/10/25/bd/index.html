<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8" />

    

    

    <title>大数据面试基础 | 小于狙击手的博客</title>
    <meta name="author" content="于印霄" />
    <meta name="keywords" content="null" />
    <meta name="description" content="大数据整理大数据的面试相关内容，主要包括namenode，hdfs读写数据，部署job流程等。 Scalacollect: Spark的collect方法，是Action类型的一个算子，收集一个弹性分布式数据集的所有元素到一个数组中。从远程集群拉取数据到driver端将大量数据汇集到一个driver节点上，将数据用数组存放，占用jvm堆内存容易造成内存溢出，只用作小型数据收集。persist:读取数据转为多个RDD时暂存；提高效率，没必要重复多次读取Shuffle的操作由于 S..." />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />

    
    <link rel="alternate" href="/atom.xml" title="小于狙击手的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/images/favicon.ico">
    

    <style type="text/css">
    @font-face {
        font-family: 'icomoon';
        src: url("/fonts/icomoon.eot?q628ml");
        src: url("/fonts/icomoon.eot?q628ml#iefix") format('embedded-opentype'),
             url("/fonts/icomoon.ttf?q628ml") format('truetype'),
             url("/fonts/icomoon.woff?q628ml") format('woff'),
             url("/fonts/icomoon.svg?q628ml#icomoon") format('svg');
        font-weight: normal;
        font-style: normal;
    }
    </style>
    <link rel="stylesheet" href="/css/style.css">

    <!--[if lt IE 9]>
    <style type="text/css">
    .nav-inner {top:0;}
    .author-meta {position:static;top:0;}
    .search-form {height:36px;}
    </style>
    <script type="text/javascript" src="https://unpkg.com/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
    <![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><main class="app">
        <header id="header" class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">小于狙击手的博客</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item" href="/categories/home">
                <span class="nav-text">首页</span>
            </a>
        
            <a class="nav-item" href="/categories/ml">
                <span class="nav-text">机器学习</span>
            </a>
        
            <a class="nav-item" href="/categories/rec">
                <span class="nav-text">推荐系统</span>
            </a>
        
            <a class="nav-item" href="/categories/BD">
                <span class="nav-text">大数据</span>
            </a>
        
            <a class="nav-item" href="/categories/code">
                <span class="nav-text">coding</span>
            </a>
        
            <a class="nav-item" href="/tags">
                <span class="nav-text">标签</span>
            </a>
        
            <a class="nav-item" href="/archives">
                <span class="nav-text">归档</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">关于我</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="https://yuyinxiao.github.io"></form>

        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#大数据"><span class="toc-number">1.</span> <span class="toc-text">大数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scala"><span class="toc-number">1.1.</span> <span class="toc-text">Scala</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle的操作"><span class="toc-number">1.1.1.</span> <span class="toc-text">Shuffle的操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#广播变量"><span class="toc-number">1.1.2.</span> <span class="toc-text">广播变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD"><span class="toc-number">1.1.3.</span> <span class="toc-text">RDD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#maven"><span class="toc-number">1.2.</span> <span class="toc-text">maven</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scope"><span class="toc-number">1.2.1.</span> <span class="toc-text">scope</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#IDEA的快捷键"><span class="toc-number">1.3.</span> <span class="toc-text">IDEA的快捷键</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop"><span class="toc-number">1.4.</span> <span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SecondaryNamenode"><span class="toc-number">1.4.1.</span> <span class="toc-text">SecondaryNamenode</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#元数据"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">元数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS读写流程"><span class="toc-number">1.4.2.</span> <span class="toc-text">HDFS读写流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#提交job应用流程"><span class="toc-number">1.4.3.</span> <span class="toc-text">提交job应用流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce"><span class="toc-number">1.4.4.</span> <span class="toc-text">MapReduce</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#详解shuffle过程"><span class="toc-number">1.4.5.</span> <span class="toc-text">详解shuffle过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#tips"><span class="toc-number">1.4.5.1.</span> <span class="toc-text">tips</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition"><span class="toc-number">1.4.6.</span> <span class="toc-text">Partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combiner"><span class="toc-number">1.4.7.</span> <span class="toc-text">Combiner</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二次排序"><span class="toc-number">1.4.8.</span> <span class="toc-text">二次排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HBase"><span class="toc-number">1.5.</span> <span class="toc-text">HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hbase-shell"><span class="toc-number">1.5.1.</span> <span class="toc-text">hbase shell</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive"><span class="toc-number">1.6.</span> <span class="toc-text">Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive表"><span class="toc-number">1.7.</span> <span class="toc-text">hive表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#内部表与外部表"><span class="toc-number">1.7.1.</span> <span class="toc-text">内部表与外部表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#加载与删除分区"><span class="toc-number">1.7.2.</span> <span class="toc-text">加载与删除分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive命令"><span class="toc-number">1.7.3.</span> <span class="toc-text">hive命令</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive"><span class="toc-number">1.8.</span> <span class="toc-text">hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#建表"><span class="toc-number">1.8.1.</span> <span class="toc-text">建表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#修改表"><span class="toc-number">1.8.2.</span> <span class="toc-text">修改表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#关键字"><span class="toc-number">1.8.3.</span> <span class="toc-text">关键字</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive与SQL"><span class="toc-number">1.8.4.</span> <span class="toc-text">Hive与SQL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka"><span class="toc-number">1.9.</span> <span class="toc-text">Kafka</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink"><span class="toc-number">1.10.</span> <span class="toc-text">Flink</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#流处理与批处理"><span class="toc-number">1.10.1.</span> <span class="toc-text">流处理与批处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Flink容错性高，快照恢复"><span class="toc-number">1.10.1.1.</span> <span class="toc-text">Flink容错性高，快照恢复</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scala基础"><span class="toc-number">1.11.</span> <span class="toc-text">Scala基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark"><span class="toc-number">1.12.</span> <span class="toc-text">Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-job资源分配"><span class="toc-number">1.12.1.</span> <span class="toc-text">Spark job资源分配</span></a></li></ol></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content">
            <div id="wrapper" class="wrapper" style="max-width: 800px">
                <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            大数据面试基础
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://yuyinxiao.github.io/2019/10/25/bd/index.html">
    
        <!-- 不蒜子统计 -->
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">阅读数 <span id="busuanzi_value_site_pv"></span>次</span>
    

    
    <i class="icon-calendar"></i>
    
    <time datetime="2019-10-25T04:02:22.000Z" itemprop="datePublished">2019-10-25</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a>
</div>


        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><p>整理大数据的面试相关内容，主要包括namenode，hdfs读写数据，部署job流程等。<br><a id="more"></a> </p>
<hr>
<h2 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h2><ul>
<li>collect: Spark的collect方法，是Action类型的一个算子，收集一个弹性分布式数据集的所有元素到一个数组中。从远程集群拉取数据到driver端将大量数据汇集到一个driver节点上，将数据用数组存放，占用jvm堆内存容易造成内存溢出，只用作小型数据收集。</li>
<li>persist:读取数据转为多个RDD时暂存；提高效率，没必要重复多次读取</li>
</ul>
<h3 id="Shuffle的操作"><a href="#Shuffle的操作" class="headerlink" title="Shuffle的操作"></a>Shuffle的操作</h3><p>由于 Shuffle 操作对性能的影响比较大，所以需要特别注意使用，以下操作都会导致 Shuffle：</p>
<ul>
<li>涉及到重新分区操作： 如 repartition 和 coalesce；</li>
<li>所有涉及到 ByKey 的操作：如 groupByKey 和 reduceByKey，但 countByKey 除外；</li>
<li>联结操作：如 cogroup 和 join。</li>
</ul>
<h3 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h3><p>每个Task任务的闭包都会持有自由变量的副本，如果变量很大且 Task 任务很多的情况下，这必然会对网络 IO 造成压力，为了解决这个情况，Spark 提供了广播变量。<strong>广播变量后不把副本变量分发到每个 Task 中，而是将其分发到每个 Executor，Executor 中的所有 Task 共享一个副本变量。</strong></p>
<h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><ul>
<li><strong>全局变量应用在rdd中运算为副本运算，变量并不改变；rdd中定义变量可改变。</strong></li>
<li>一个RDD由多个分区（Partitions）组成。<strong>对于RDD的每个分区会被一个计算任务所处理，用户可以在创建 RDD 时指定其分区个数，如果没有指定，则默认采用程序所分配到的 CPU 的核心数；</strong> RDD的每次转换都会生成一个新的依赖关系，如果分区数据丢失后，可以通过依赖关系重新计算对RDD的所有分区进行重新计算；</li>
<li>Key-Value 型的 RDD 还拥有 Partitioner(分区器)，用于决定数据被存储在哪个分区中，目前 Spark 中支持 HashPartitioner(按照哈希分区) 和 RangeParationer(按照范围进行分区)；</li>
<li><p>Spark进行任务调度会尽可能的将计算任务分配到其所要处理数据块的存储位置。</p>
</li>
<li><p>RDD 支持两种类型的操作：transformations（转换，从现有数据集创建新数据集）和 actions（在数据集上运行计算后将值返回到驱动程序）。</p>
</li>
<li>RDD 中的所有转换操作都是惰性的，它们只是记住这些转换操作，但不会立即执行，只有遇到 action 操作后才会真正的进行计算，这类似于函数式编程中的惰性求值</li>
</ul>
<h2 id="maven"><a href="#maven" class="headerlink" title="maven"></a>maven</h2><p>mvn clean compile  编译<br>mvn clean test 测试<br><strong>mvn clean package 打包</strong><br>mvn clean install 把生成的jar/war包复制到本地repository(就是~/.m2/repository下面)<br>mvn clean deploy 把生成的jar/war包发送到远程repository（建议配置了私服，那就是往私服发送了）<br>mvn cargo:run 通过cargo插件，把生成的war包部署到本地服务器，并启动。（注意要先运行 mvn clean package 打包）<br>mvn cargo:redeploy 通过cargo插件，把生成的war包部署到远程服务器：如果已经有了，就先undeploy再deploy，如果没有直接deploy（注意要先运行 mvn clean package 打包，并且远程服务器是启动的）</p>
<h3 id="scope"><a href="#scope" class="headerlink" title="scope"></a>scope</h3><p>org.apache.等外公司名下的包在集群上有相关容器提供，故scope为provide然后提交；<br>私服内公司名下的工程下的包集群上是没有容器提供的，故scope不可以添加provide默认compile，然后提交；<br>本地运行测试时，在应用中勾选“include dependencies with Provided scope”，后成功运行。</p>
<h2 id="IDEA的快捷键"><a href="#IDEA的快捷键" class="headerlink" title="IDEA的快捷键"></a>IDEA的快捷键</h2><p>⌘P 显示方法的参数信息<br>⌘⌥T 包围代码（使用if..else, try..catch, for, synchronized等包围选中的代码）<br>⌘⌥｜切换列编辑<br>⌥↩ 显示意向动作和快速修复代码<br>⌃⌥O 优化import<br>^⌥B 重命名变量<br>⌘+ / ⌘- 展开 / 折叠代码块<br>⌃R 运行<br>⌃D 调试<br>⌘L 在当前文件跳转到某一行的指定处</p>
<h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><div class="table-container">
<table>
<thead>
<tr>
<th>command</th>
<th>func</th>
</tr>
</thead>
<tbody>
<tr>
<td>mkdir -p /a/b/c</td>
<td>父目录不存在时会创建，不会报错</td>
</tr>
<tr>
<td>hadoop fs -germerge -nl /hdfs_dir  /local_dir/</td>
<td>同名则会覆盖；nl在不同文件之间会空一行</td>
</tr>
<tr>
<td>hadoop fs -du -s -h /hdfs_dir</td>
<td>文件夹下数据大小</td>
</tr>
<tr>
<td>hadoop fs -test -e：</td>
<td>如果路径存在，则返回 0;-s：如果路径不为空，则返回 0。</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nohup command aaa.sh &gt;&gt; yu.out &amp;</span><br><span class="line">jobs -l</span><br><span class="line">kill -9 进程号</span><br></pre></td></tr></table></figure>
<h3 id="SecondaryNamenode"><a href="#SecondaryNamenode" class="headerlink" title="SecondaryNamenode"></a>SecondaryNamenode</h3><p>SecondaryNameNode：周期性保存NameNode的元数据，在namenode失效时恢复出namenode上的元数据。</p>
<h4 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h4><p>包括文件镜像数据FSImage和编辑日志EditLog。FSImage相当于HDFS的检查点，namenode启动时候会读取FSImage的内容到内存，并将其与EditLog日志中的所有修改信息合并生成新的FSImage；在namenode运行过程中，所有关于HDFS的修改都将写入EditLog。这样，如果namenode失效，可以通过SecondaryNameNode中保存的FSImage和EditLog数据恢复出namenode最近的状态。</p>
<h3 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h3><ol>
<li>向HDFS写数据<br><img src="/2019/10/25/bd/write.png" alt></li>
<li>从HDFS读数据<br><img src="/2019/10/25/bd/read.png" alt></li>
</ol>
<h3 id="提交job应用流程"><a href="#提交job应用流程" class="headerlink" title="提交job应用流程"></a>提交job应用流程</h3><p>提交job的全过程：提交job给YARN，执行MapReduce、HDFS读数据，HDFS写数据。<br>提交job给YARN的过程：提交job，job的初始化，任务分配，任务运行，作业完成<br>作业换队列：<code>yarn application -movetoqueue application_1563931265452_2009268 -queue root.a.b</code></p>
<hr>
<p><img src="/2019/10/25/bd/job.png" alt></p>
<p>1、客户端向Resource Manager申请一个job_id和job资源的提交路径；提交后向Resource manager申请运行 MRAppMaster。</p>
<p>2、Resource Manager将job分配给某一个空闲的NodeManager，创建容器得到MRAppmaster，再把客户端提交的资源下载到本地。</p>
<p>3、MRAppMaster向Resource Manager申请运行多个mapTask任务资源。Resource Manager将mapTask分配给其他NodeManager。</p>
<p>4、Resource Manager向NodeManager发送脚本启动map任务，等所有map任务运行完毕后，向Resource Manager申请容器，运行 reduce任务，运行完后向Resource Manager申请注销。</p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>详解shuffle过程：<br>map-&gt;buff环形缓存区-&gt;溢出合并与归并排序-&gt;按分区号将不同的mapTask数据合并到reduceTask-&gt;同一reduceTask归并排序-&gt;对reduceTask中的value计算</p>
<hr>
<p>从文件中获取block<br><img src="/2019/10/25/bd/spark.png" alt></p>
<ul>
<li>本文件内若干个Block合并成一个输入分片split；不能跨越文件；</li>
<li>一个split对应一个Task；</li>
<li>一个Task执行结果对应RDD的partition<strong>增大分区数，增大task数，增大并行度</strong></li>
<li>一个Executor数目包含多个core；</li>
</ul>
<p><img src="/2019/10/25/bd/mr.jpg" alt="avatar"></p>
<p>map task读取文件写入环形缓冲区（100M），一次溢出后按照key进行hash分区，多次溢出的文件按照分区合并(归并排序)；对多个map task的相同分区内的key进行归并排序，然后传给reduce task。</p>
<h3 id="详解shuffle过程"><a href="#详解shuffle过程" class="headerlink" title="详解shuffle过程"></a>详解shuffle过程</h3><p><img src="/2019/10/25/bd/shuffle1.png" alt><br><img src="/2019/10/25/bd/shuffle2.png" alt></p>
<p>上面的流程是整个mapreduce最全工作流程，但是shuffle过程只是从第7步开始到第16步结束，具体shuffle过程详解，如下：</p>
<ol>
<li>maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</li>
<li>从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li>
<li>多个溢出文件会被合并成大的溢出文件</li>
<li>在溢出过程中，及合并的过程中，都要调用partitoner进行分组和针对key进行排序</li>
<li>reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</li>
<li>reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）</li>
<li>合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</li>
</ol>
<h4 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h4><ul>
<li>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</li>
<li>缓冲区的大小可以通过参数调整，参数：io.sort.mb  默认100M</li>
</ul>
<p><img src="/2019/10/25/bd/mr.png" alt="avatar"></p>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>map端输出(k,v)对key取hash值实现分区负载均衡算法</p>
<h3 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h3><p>每一个map都可能会产生大量的本地输出，Combiner的作用就是对<strong>本地的map端的输出先做一次合并</strong>key下value以list形式存储，<strong>大大减少在map和reduce节点之间的数据传输量，以提高网络IO性能</strong>是MapReduce的一种优化手段之一。就在part下对相同的key提前合并一下</p>
<ul>
<li>combiner是MR程序中Mapper和Reducer之外的一种组件</li>
<li>combiner组件的父类就是Reducer</li>
<li>combiner和reducer的区别在于运行的位置：Combiner是在每一个maptask所在的节点运行，Reducer是接收全局所有Mapper的输出结果；</li>
<li>combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量</li>
<li>combiner能够应用的前提是不能影响最终的业务逻辑，而且，combiner的输出kv应该跟reducer的输入kv类型要对应起来</li>
</ul>
<h3 id="二次排序"><a href="#二次排序" class="headerlink" title="二次排序"></a>二次排序</h3><p>如何做到在Reduce阶段，先对Key排序，再对Value排序<br>该问题通常称为”二次排序“，最常用的方法是将Value放到Key中，实现一个组合Key，然后自定义Key排序规则（为Key实现一个WritableComparable）</p>
<h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><ul>
<li>行键：是hbase表自带的，每个行键对应一条数据。</li>
<li>列族：是创建表时指定的，为列的集合，每个列族作为一个文件单独存储，存储的数据都是字节数组，其中数据可以有很多，通过时间戳来区分。</li>
<li>物理模型：整个hbase表会拆分成多个region，每个region记录着行键的起始点保存在不同的节点上，查询时就是对各个节点的并行查询，当region很大时使用.META表存储各个region的起始点，-ROOT又可以存储.META的起始点。</li>
</ul>
<ol>
<li>Rowkey的设计原则：各个列族数据平衡，长度原则、相邻原则，创建表的时候设置表放入regionserver缓存中，避免自动增长和时间，使用字节数组代替string，最大长度64kb，最好16字节以内，按天分表，两个字节散列，四个字节存储时分毫秒。</li>
<li>列族的设计原则：尽可能少(按照列族进行存储，按照region进行读取，不必要的io操作)，经常和不经常使用的两类数据放入不同列族中，列族名字尽可能短</li>
</ol>
<h3 id="hbase-shell"><a href="#hbase-shell" class="headerlink" title="hbase shell"></a>hbase shell</h3><p>hbase扫的是key，非视频id，哈希后的数据对应的key<br><figure class="highlight plain"><figcaption><span>'hbasehhhhh','000005020000'```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">```scan &apos;hbasehhhhh&apos;</span><br></pre></td></tr></table></figure></p>
<h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以某字符连接字段</span></span><br><span class="line">concat_ws：<span class="keyword">SELECT</span> <span class="keyword">CONCAT_WS</span>(<span class="string">'_'</span>,<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">AS</span> con_ws <span class="keyword">FROM</span> info;</span><br><span class="line"><span class="comment">#对字段A分组，队字段B降序且取字段B的top3</span></span><br><span class="line">row_number：<span class="keyword">select</span> <span class="keyword">id</span>,age,<span class="keyword">name</span>,sex <span class="keyword">from</span></span><br><span class="line">(<span class="keyword">select</span> <span class="keyword">id</span>,age,<span class="keyword">name</span>,sex,row_number() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> sex <span class="keyword">order</span> <span class="keyword">by</span> age <span class="keyword">desc</span>) <span class="keyword">as</span> rownumber <span class="keyword">from</span> rownumber) temp <span class="keyword">where</span> rownumber&lt;<span class="number">3</span> </span><br><span class="line"><span class="comment">#条件真值与假值</span></span><br><span class="line">case..when：<span class="keyword">case</span> tb1.os <span class="keyword">when</span> <span class="string">'android'</span> <span class="keyword">then</span> <span class="string">'android'</span> <span class="keyword">when</span> <span class="string">'ios'</span> <span class="keyword">then</span> <span class="string">'iPhone'</span> <span class="keyword">else</span> <span class="string">'PC'</span> <span class="keyword">end</span> <span class="keyword">as</span> os</span><br><span class="line"><span class="comment">##[&#123;"name":"王二狗","sex":"男","age":"25"&#125;,&#123;"name":"李狗嗨","sex":"男","age":"47"&#125;]</span></span><br><span class="line">get_json_object：</span><br><span class="line"><span class="number">1.</span><span class="keyword">SELECT</span> get_json_object(xjson,<span class="string">"$.[0]"</span>) <span class="keyword">FROM</span> person;</span><br><span class="line">2.SELECT get_json_object(xjson,"$.[0].age") FROM person;</span><br></pre></td></tr></table></figure>
<h2 id="hive表"><a href="#hive表" class="headerlink" title="hive表"></a>hive表</h2><h3 id="内部表与外部表"><a href="#内部表与外部表" class="headerlink" title="内部表与外部表"></a>内部表与外部表</h3><ol>
<li>一般为内部表，<strong>删除内部表时相应数据也会删除</strong></li>
<li>内部表数据由Hive自身管理，外部表数据由HDFS管理。</li>
<li>内部表数据存储在hive.metastore.warehouse.dir【默认:/user/hive/warehouse】，外部表数据存储位置由用户自己决定。</li>
<li>加载内部表数据后会把数据源删除，很像”剪切/移动”。<strong>删除内部表会直接删除元数据【metadata】及存储数据</strong></li>
<li>加载外部表没有mv到数据仓库目录，只是关联上数据格式和数据位置，Hive就能直接访问外部数据。<strong>删除外部表仅仅删除元数据，HDFS上的文件不会被删除。</strong></li>
</ol>
<h3 id="加载与删除分区"><a href="#加载与删除分区" class="headerlink" title="加载与删除分区"></a>加载与删除分区</h3><ul>
<li>外部分区表删除分区，只会删除元数据，相应的目录和文件并不会删除；</li>
<li>内部表删除分区，既会删除元数据，也会删除相应的目录和数据文件；</li>
</ul>
<h3 id="hive命令"><a href="#hive命令" class="headerlink" title="hive命令"></a>hive命令</h3><h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">use qiyu_feature;</span><br><span class="line">create table update_user_mobile_brand_day(</span><br><span class="line">uid string comment &apos;uid&apos;,</span><br><span class="line">ctiy_id string comment &apos;城市&apos;,</span><br><span class="line">brand string comment &apos;手机品牌&apos;,</span><br><span class="line">mkey string comment &apos;渠道mkey&apos;)</span><br><span class="line">partitioned by (dt string) row format delimited fields terminated by &apos;\t&apos; stored as textfile;</span><br></pre></td></tr></table></figure>
<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><ol>
<li>添加字段 <code>alter table table add columns(mkey string);</code></li>
<li>修改表名 <code>alter table table_name rename ti new_table_name;</code></li>
<li>修改列名 <code>alter table table_name change old_name new_name data_type first col1 after col2;</code></li>
<li>增加分区 <code>alter table table_name add if not exists partition (dt=&#39;2019-12-01&#39;) location &#39;/data/a/b/2019-12-01&#39;;</code></li>
<li>删除分区 <code>alter table table_name drop if exists partition (dt=&#39;2019-12-01&#39;);</code></li>
</ol>
<h3 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a>关键字</h3><div class="table-container">
<table>
<thead>
<tr>
<th>command</th>
<th>func</th>
</tr>
</thead>
<tbody>
<tr>
<td>percentile_approxc</td>
<td><code>percentile_approx(cast(playtime as int),0.5) as mwt</code></td>
</tr>
<tr>
<td>cast(col as int) as res</td>
<td>列做类型转换</td>
</tr>
<tr>
<td>round</td>
<td>四舍五入</td>
</tr>
<tr>
<td>ceil</td>
<td>向上取整</td>
</tr>
<tr>
<td>floor</td>
<td>向下取整</td>
</tr>
<tr>
<td>lower：转成小写</td>
<td><code>select lower(&#39;Hive&#39;);</code> —hive</td>
</tr>
<tr>
<td>upper：转成大写</td>
<td><code>select lower(&#39;Hive&#39;);</code> —HIVE</td>
</tr>
<tr>
<td>length：长度</td>
<td><code>select length(&#39;Hive&#39;);</code> —4</td>
</tr>
<tr>
<td>concat：拼接字符串</td>
<td><code>select concat(&#39;hello&#39;,&#39;Hive&#39;);</code> —helloHive</td>
</tr>
<tr>
<td>substr：求子串</td>
<td><code>select substr(&#39;hive&#39;,2);</code> —ive <code>select substr(&#39;hive&#39;,2,1);</code> —i</td>
</tr>
<tr>
<td>trim：去掉前后的空格</td>
<td><code>select trim(&#39;  hive   &#39;);</code> -hive</td>
</tr>
<tr>
<td>lpad：左填充</td>
<td><code>select lpad(&#39;hive&#39;,10,&#39;#&#39;);</code> —######hive</td>
</tr>
<tr>
<td>rpad：右填充</td>
<td><code>select rpad(&#39;hive&#39;,10,&#39;#&#39;);</code> —hive######</td>
</tr>
<tr>
<td>to_date</td>
<td><code>select to_date(&#39;2015-05-22 15:34:23&#39;);</code> —2015-05-22</td>
</tr>
<tr>
<td>year</td>
<td><code>select year(&#39;2015-05-22 15:34:23&#39;);</code> —2015</td>
</tr>
<tr>
<td>month</td>
<td><code>select month(&#39;2015-05-22 15:34:23&#39;);</code> —5</td>
</tr>
<tr>
<td>day</td>
<td><code>select day(&#39;2015-05-22 15:34:23&#39;);</code> —22</td>
</tr>
<tr>
<td>weekofyear</td>
<td><code>select weekofyear(&#39;2015-05-22 15:34:23&#39;);</code> —21</td>
</tr>
<tr>
<td>datediff</td>
<td><code>select datediff(&#39;2015-05-22 15:34:23&#39;,&#39;2015-05-29 15:34:23&#39;);</code> —[-7]</td>
</tr>
<tr>
<td>date_add</td>
<td><code>select date_add(&#39;2015-05-22 15:34:23&#39;,2);</code> —2015-05-24</td>
</tr>
<tr>
<td>date_sub</td>
<td><code>select date_sub(&#39;2015-05-22 15:34:23&#39;,2);</code> —2015-05-20</td>
</tr>
<tr>
<td>case……when</td>
<td><code>select ename,job,sal,case job when &#39;president&#39; then sal+100 when &#39;manager&#39; then sal+800 else sal+400 end from emp;</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Hive与SQL"><a href="#Hive与SQL" class="headerlink" title="Hive与SQL"></a>Hive与SQL</h3><ul>
<li>数据存储位置不同：hive是把数据存储在hdfs上，mysql数据是存储在自己的系统中</li>
<li>数据格式：hive数据格式用户可以自定义，mysql有自己的系统定义格式</li>
<li>数据更新：hive不支持数据更新，只可以读，不可以写，而sql支持数据更新</li>
<li>索引：hive没有索引，因此查询数据的时候是通过mapreduce很暴力的把数据都查询一遍，也造成了hive查询数据速度很慢的原因，而mysql有索引；</li>
<li>延迟性：hive延迟性高，原因就是上边一点所说的，而mysql延迟性低；</li>
<li>数据规模：hive存储的数据量超级大，而mysql只是存储一些少量的业务数据；</li>
<li>底层执行原理：hive底层是用的mapreduce，而mysql是excutor执行器</li>
</ul>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>消息是kafka主要处理的对象，在某个主题之下，生产者向主题发布新消息，消费者从主题订阅新消息。<br>异步处理、应用解耦、流量缓冲、日志采集</p>
<ul>
<li>消息队列实现订单系统与库存系统的解耦，到应用层的解耦，防止短时间压垮应用；</li>
<li>负责日志数据接收存储与转发</li>
</ul>
<h2 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h2><h3 id="流处理与批处理"><a href="#流处理与批处理" class="headerlink" title="流处理与批处理"></a>流处理与批处理</h3><ol>
<li>流处理系统：一条数据被处理完成后，序列化到缓存中，通过网络传输到下一个节点，由下一个节点继续处理。</li>
<li>批处理系统：一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才数据通过网络传输到下一个节点。</li>
</ol>
<ul>
<li>数据传输的两个极端：流处理系统对低延迟；批处理系统对高吞吐量。</li>
<li><strong>Flink是两个极端的折中，以固定缓存块为单位传输，且缓存块超时值是可调的</strong>。如果缓存块为0，则是低延迟的流处理系统；如果缓存块的超时值为无限大，则是高吞吐量的批处理系统。</li>
</ul>
<h4 id="Flink容错性高，快照恢复"><a href="#Flink容错性高，快照恢复" class="headerlink" title="Flink容错性高，快照恢复"></a>Flink容错性高，快照恢复</h4><p>Flink基于分布式快照与可部分重发的数据源实现了容错。用户可自定义对整个Job进行快照的时间间隔，当任务失败时，Flink会将整个Job恢复到最近一次快照，并从数据源重发快照之后的数据。</p>
<h2 id="Scala基础"><a href="#Scala基础" class="headerlink" title="Scala基础"></a>Scala基础</h2><ul>
<li>case class：自动生成常用方法(equals&amp;hashCode,toString,copy)；自动生成伴生对象；实现了 apply 方法让你不需要通过 new 来创建类实例</li>
<li>宽依赖，窄依赖：窄依赖：map和filter，一个父RDD对应一个子RDD；宽依赖：一个父RDD对应非全部的子RDD；</li>
<li>Transformation与Action：Transformation 操作是延迟计算的，也就是说从一个RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算（map, filter）；Action是count之类的算子出发计算；</li>
<li>存在shuffle的spark算子：distinct、groupByKey，reduceByKey、repartition，coalesce、interection，join；</li>
</ul>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="Spark-job资源分配"><a href="#Spark-job资源分配" class="headerlink" title="Spark job资源分配"></a>Spark job资源分配</h3><div class="table-container">
<table>
<thead>
<tr>
<th>config</th>
<th>num</th>
<th>annotation</th>
</tr>
</thead>
<tbody>
<tr>
<td>driver-memory</td>
<td>4g</td>
<td>driver使用的内存，不可超过单机的 core 总数。</td>
</tr>
<tr>
<td>num-executors</td>
<td>2</td>
<td>创建多少个 executor。</td>
</tr>
<tr>
<td>executor-memory</td>
<td>2g</td>
<td>各个 executor使用的最大内存，不可超过单机的最大可使用内存。</td>
</tr>
<tr>
<td>executor-cores</td>
<td>2</td>
<td>各个 executor 使用的并发线程数目，也即每个 executor 最大可并发执行的 Task 数目。</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2019/10/25/bd/cluster.jpg" alt="avatar"></p>
<ul>
<li>数据倾斜：某个key下value过多，reduce_task处理任务过重导致运行特别慢。shuffle出现在期间。造成后果：有得任务执行完毕，某个任务执行很慢而且可能出现OOM错误；一般增大执行器与核数，并行数，自定义partition</li>
<li>尽量减少spark任务的空间占用，同时加速spark任务运行速度</li>
</ul>

        
    </section>
</article>



<a id="pagenext" href="/2019/10/25/Sql/" class="article-next" title="Sql"><i class="icon-arrow-right"></i></a>


<a id="pageprev" href="/2019/10/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" class="article-prev" title="计算机网络"><i class="icon-arrow-left"></i></a>



<div class="comments">
    <div id="comments"></div>
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>
    new Gitalk({
        clientID: "a9a645b881c78d12baa8",
        clientSecret: "d7e2f110f4885b3fa11894f3ddd2cd46523889fd",
        repo: "yuyinxiao.github.io",
        owner: "yuyinxiao",
        admin: ["yuyinxiao"],
        id: "2019/10/25/bd",
        distractionFreeMode: true,
        title: "大数据面试基础",
        body: "https://yuyinxiao.github.io/2019/10/25/bd/",
        labels: ["大数据"]
    }).render('comments');
    </script>
</div>


            </div>
        </div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>

    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?ff62cebe12c54c12ef10722f77d75303";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    
    
        <!-- 不蒜子统计 -->
        <span id="busuanzi_container_site_pv">
                本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>
        <span class="post-meta-divider">|</span>
        <span id="busuanzi_container_site_uv" style='display:none'>
                本站访客数<span id="busuanzi_value_site_uv"></span>人
        </span>
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
</footer>

    </main>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }

            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle();
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp();
            }, 3000);
        }
    });
    </script>
    
        <script src="/js/scrollspy.min.js"></script>
        <script type="text/javascript">
        $(document.body).scrollspy({target: '#aside-inner'});

        $(window).on('resize', function() {
            var hw = $('#header').width();
            var ww = $('#wrapper').width();
            var space = ($(this).width() - hw - ww) / 2 / 2;

            var pageprev = $('#pageprev');
            var pagenext = $('#pagenext');
            var avg = (pageprev.width() + pagenext.width()) / 2

            if(space > avg) {
                var len = space - avg / 2;
                var styles = {position: 'fixed', top: '50%', marginTop: - (pageprev.width() + pagenext.width()) / 4}
                pageprev.css($.extend({left: hw + len}, styles));
                pagenext.css($.extend({right: len}, styles));
            } else {
                pageprev.removeAttr('style');
                pagenext.removeAttr('style');
            }
        }).trigger('resize');
        </script>
    

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
